1. P0: Explain why in the simplex method, the optimal solution must have (n-m) of the components equal to zero.
2. P1: Read the answer here for how online linear regression can be done with Newtons method: https://stats.stackexchange.com/questions/6920/efficient-online-linear-regression/369046#369046.
3. P0: In Newton's method, we repeatedly solve quadratic optimization problems. Does that mean that we repeatedly solve linear optimization problems in gradient descent? Why or why not?
4. P1: How in the proof of proposition 4.4 is independence concluded?
5. P0: What is topological sorting of a graph? Describe how it is accomplished with DFS.
6. P0: Summarize connection between binary classification and hypoth-test blogs. What do the different areas in the distribution plots mean in both contexts?


1. Here's why in the Simplex method the optimal solution must have (n-m) components equal to zero:
	1. If we have M independent equations and N variables where N=M, then there is no simplex. The solution is just one point.
	2. When we make the number of variables greater than the number of equations, we have an underdetermined system of equations, meaning there's a feasible space of solutions that would solve the system.
	3. Now in this example, not only do we have a system of equations where N variables > M equations, but we have constraints that say each of the N variables must be greater than or equal to zero. In vector notation this is written as X >= 0 where X represents X1, X2, X3...XN
	4. When we add these X >= 0 constraints, we then essentially partition the space on the positive side of each dimension's axes. For example if it were only 2D, this would be the 1st quadrant.
	5. So we have M equations and N variables. Each of the M equations reduces the dimensionality of the solution space, but since N is greater than M, this leaves N-M dimensions that can essentially be anything. 
	6. Now we circle back to the original goal of the problem, which was to MINIMIZE Mx = B with the constraints that all variables have to be >= 0. This is the key to why N-M variables have to be zero.
	7. The reason, if they weren't zero, that means by default the solution would be INSIDE the simplex, not on the boundary. Which means that there are 2 possible directions you could move in to get a different answer to Mx = b, and of course one will make the objective function greater and one will make the objective function smaller. 
	8. The only way that you're definitely at a minimum is when you're at a vertex of the simplex, because when you're at a vertex there's no direction where you can also move in the opposite direction. Now which vertex it is is another story and there are n choose m different vertices in the simplex. 

	2 and 3
	. The idea behind online linear regression comes from a matrix multiplication rule that says two matrices multiplied together are the sum of the matrices generated by the outer product of the first matrices columns and the second matrices rows. So we have our solution for the betas which is (X^T * X)^-1 X^T * y. If we get a new data point and we just need to multiply x_new * x_new transpose, invert it, then multiply that by x_new*y_new

	4. In proposition 4.4, the proof is reached in the following steps.
		![[proof_4.4_pt1.jpg]]
		![[proof_4.4_pt2.jpg]]
		![[proof_4.4_pt3.jpg]]
1. Topological sorting of a graph is a procedure that can be used on a directed acyclic graph to print the nodes in a graph such that every parent node is printed before it's descendants. The way the algorithm works is that it's regular depth first search except that whenever a node is "finished" (meaning all its descendants have been visited), you append that node to the FRONT of a linked list. This produces a "work backwards approach", as the root node is the last thing appended to the front of the linked list. It needs to be on a directed graph because if you can go both ways, then there are no parent child relationships, and it needs to be acyclic because if it isn't, you can run into the issue some grandparent contradictions. 
2. The summary between hypothesis testing and binary classification is that in both cases there are 4 different types of outcomes. I will start with binary classification since it is more straight forward. In Binary classification you have two distributions that may or may not overlap. The actual lines that draw up the distributions represent the ground truth value of what we're trying to classify. The X axis represents the "radar score". the y axis represents the probability density of that "radar score"? The decision threshold represents at value "radar score" we classify it as a "positive" or a "negative". So essentially there are 4 things that can happen. A true positive, true negative, false positive, and false negative. A true positive is when the radar score falls below the decision threshold, and the drawn out line above it is the line that represents the ACTUAL positives (its green in rohits picture). The true negatives are when the radar score falls above the decision threshold and the line above it represents ACTUAL negative (red line). Now here's where the overlap comes in. If the score is above the threshold but the line above it is green, that means it's a FALSE NEGATIVE. We classified it as negative but actually it was positive. And if the score is below the threshold but the line above it is red, then it's a FALSE POSITIVE, meaning we thought it was a positive result but it was actually negative.

	Now let's move to the slightly trickier case which is hypothesis testing. It's the same concept  but the way it's applied is a little more nuanced, and the concepts of "positive" and "negative" represent slightly different things. In this example, the X axis represents values of the test statistic and the Y axis represents probability density of the that value. The left distribution represents the cases where we fail to reject the null hypothesis. The right distribution represents cases where we reject the null hypothesis and switch to the alternate hypothesis. A positive in this case is when we reject the null hypothesis, and a negative is when we fail to reject the null hypothesis. Therefore, a FALSE POSITIVE is when we reject the null hypothesis and we shouldn't have. A FALSE NEGATIVE is when we should have rejected the null hypothesis but we did not. And true positive and true negative are straightforward.


7.