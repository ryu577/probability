

Happy new year!

Note linear algebra book and ML with probability course updated in [[Resources]].
# Algebra exercises
1. If $a^2-b^2=8$ and $ab=2$, find $a^4+b^4$.
2. $f(x)$ is a function s.t. $f(x)+3f(8-x) = x$. Find the value of $f(2)$.
3. There is a fourth degree polynomial, $f$. This polynomial is always greater than $y=x$. We further know that $f(2)=2$ and $f(4)=4$. Find any polynomial, $f$ that satisfies all of these conditions.
# Regular
1. P0: Prove that if we start from a vector specifying the probability of being in each state for a finite state Markov chain, prove that after going through any number of steps, the vector will remain a valid probability vector.
2. P1: When we solve the steady state equations of a Markov chain, we get $n+1$ equations but only $n$ variables (the steady state probabilities). Then, how is it that the system still has a unique solution? Don't we have more equations than variables? Either explain this. If you can't, write up a question on mathexchange.
3. P0: Read this blog: https://medium.com/towards-data-science/a-birds-eye-view-of-linear-algebra-why-is-matrix-multiplication-like-that-a4d94067651e. Explain to me why matrix multiplication is associative.
4. P0: Let's take a Markov chain that *isn't* irreducible. Does it have a steady states? What happens if you construct the steady state system of equations and solve them? Do we get a solution? What does the solution represent? Demonstrate with examples.
5. P0: Complete Q2 and Q4 from [[231231]].
6. P1: Explain why $X_1+X_2$ (where the two are i.i.d.) and $2X_1$ are not the same random variable. Which of them has larger variance? Which of them has a larger expected value?
7. P0: Leetcode graph question: https://leetcode.com/problems/course-schedule/description/.
8. P2: Prove that the parenthesis theorem doesn't hold for BFS.



# Algebra

1. ![[algebra_1.png]]

2. ![[algebra_2.png]]
# Regular 

1. ![[markov_probability_vector_proof.png]]
2. ![[markov_linear_algebra.png]]

3. 
4. Singular matrix, no solution


5. AI Betting Edge Steady State
	~~~Python
	import numpy as np
from math import comb
i = 15


def binomial(n,k,p):
	return comb(n,k)*(p**k)*((1-p)**(n-k))

def new_subscriber(i):
	return (.5**i)/(1+(.5**i))



matrix = np.zeros((i+1,i+1))


for row in range(matrix.shape[0]-1):
	for col in range(matrix.shape[0]):
		if col==0:
			if row > col:
				matrix[row][col] = (.1**row)*(1-new_subscriber(row))
			elif row == col:
				matrix[row][col] = 1-new_subscriber(row)
		elif row == col:
			matrix[row][col] = (1 - new_subscriber(row))*(.9**row) + (binomial(row,1,.1)*new_subscriber(row))
		elif col-row==1:
			matrix[row][col] = new_subscriber(row)*(.9**row)
		elif row > col:
			diff = row-col
			first_way = binomial(row,diff,.1)*(1-new_subscriber(row))
			second_way = binomial(row,diff+1,.1)*new_subscriber(row)
			if row!=i:
				matrix[row][col] = first_way+second_way
			else:
				matrix[row][col] = first_way

for col in range(matrix.shape[0]):
	diff = i-col
	matrix[i,col]=binomial(i,diff,.1)

print(matrix.sum(axis=1))

A = matrix.T
A_sub = A - np.eye(i+1)

B = [0 for val in range(i+1)]
B.append(1)
B = np.expand_dims(np.array(B),-1)

newrow = [1 for val in range(i+1)]

A_sub = np.vstack([A_sub, newrow])


A_new = np.dot(A_sub.T,A_sub)
B_new = np.dot(A_sub.T,B)


results = np.linalg.solve(A_new,B_new)
	~~~


Different species of Markov Chains:
	1. Irreducible - all states can communicate with each other, only one class
	2. Finite state markov chain - finite number of states, gamblers ruin with walking away at 0 or fixed upper bound
	3. Infinite state markov chain - infinite number of states, random walk
	4. recurrent markov chain - all states will be visited an infinite number of times in expectation as n goes to infinity
	5. transient markov chain - some states will never be visited again in expectation as n goes to infinity
	6. positive recurrent markov chain - same thing as recurrent except with the added condition that the expected number of time till a state returns to the same state is finite. Small technicality. 
	7. aperiodic markov chain - each state can be visited in any number of steps, period of 1
	8. periodic markov chain - markov chain with period > 1
	9. ergodic markov  - a chaiin that's both positive recurrent and aperiodic


7.  leetcode
   ~~~Python
   class Solution:

    def canFinish(self, numCourses: int, prerequisites: List[List[int]]) -> bool:

        nodes = []
        adjacency_list = {}

        for val in prerequisites:
            parent = Node(val[1])
            child = Node(val[0])
        adjacency_list[parent] = child
  

        white = []
        adjacency = {}

        for val in prerequisites:
            if val[1] in adjacency:
                adjacency[val[1]].append(val[0])
            else:
                adjacency[val[1]]=[val[0]]

            white.append(val[0])
            white.append(val[1])

        nodes = white.copy()
        white = list(set(white))
        gray = []
        black = []

        global cycle
        cycle = True

  

        def dfs(white,gray,black,adjacency,node):

            global cycle
            gray.append(node)
            if node in adjacency:
                for val in adjacency[node]:
                    if val in white:
                        white.remove(val)
                        dfs(white,gray,black,adjacency,val)
                    elif val in gray:
                        cycle = False

            gray.remove(node)
            black.append(node)

            return

        for val in nodes:
            if val in white:
                white.remove(val)
                dfs(white,gray,black,adjacency,val)

        return cycle
   ~~~