1. P0: Prove that to get the the 2 by 2 Markov chain with only good and bad states, we have to divide by $\pi_1+\pi_2$. 
2. P0: Example 4.24 of Ross book: demonstrate that our approach of combining states is equivalent to his approach with a lot of algebra.
3. P0: The non-irreducible Markov chain you were working on (Ross book); explain what happens to it after a long time using Eigen value approach we discussed.
4. P0: Prove that if you try to do parenthesis theorem for BFS, it won't work. The counter-example you provided last time, code it up. When vertex is marked grey, parenthesis open. When black, its closed.
5. P1: Implement DFS without recursion (exercise 22.3-7, CLR book).
6. P1: Exercise 22.3-9 and 22.3-10 of CLR book
7. P2: Balmer interview question - what is the expected value of the game.

remaining: 1,5,6

1. Didn't figure this out
2. ![[simplify_markov_chain_pt_1.jpg]] keywords: markov chain, rates, ross example
![[simplify_markov_chain_pt_2.jpg]]


3 keywords: steady state, markov chain, irreducible, eigenvectors
~~~python
import numpy as np
from 
numpy import linalg as LA

matrix = np.array([[.5,.5,0,0,0],
				   [.5,.5,0,0,0],
				   [0,0,.5,.5,0],
				   [0,0,.5,.5,0],
				   [.25,.25,0,0,.5]
				   ])


matrix_shape = matrix.shape[0]
eigenvalues, eigenvectors = LA.eig(matrix)
eigenvectors_inverse = LA.inv(eigenvectors)


lambda_matrix = np.zeros((matrix_shape, matrix_shape))
np.fill_diagonal(lambda_matrix, eigenvalues)
lambda_decayed = LA.matrix_power(lambda_matrix,10000)




result = np.matmul(eigenvectors,np.matmul(lambda_decayed,eigenvectors_inverse))
print(LA.matrix_power(matrix,10000))
print(result)

result = [[0.5 0.5 0.  0.  0. ]
		 [0.5 0.5 0.  0.  0. ]
		 [0.  0.  0.5 0.5 0. ]
		 [0.  0.  0.5 0.5 0. ]
		 [0.5 0.5 0.  0.  0. ]]


~~~


Each row of the result matrix represents the steady state probability given you start in that row state. 


4 Below we see it parenthesis theorem does not work for BFS
keywords: bfs, parenthesis theorem, clr, dfs
~~~python import numpy as np
import numpy as np
from collections import deque
import time
global time, stack
stack = deque()
time = 0

class Node:
	def __init__(self, number, d = np.inf, pi=None, color='White',d_time=None,f_time=None):
		self.number = number
		self.name = str(number)
		self.d = d
		self.pi = pi 
		self.color = color
		self.d_time = d_time
		self.f_time = f_time

	def __repr__(self):
		return self.name


nodes = [Node(0),Node(1),Node(2),Node(3),Node(4),Node(5),Node(6),Node(7),Node(8)]


graph = {nodes[5]:[nodes[1],nodes[6]],nodes[1]:[nodes[0],nodes[2]],nodes[2]:[nodes[3]],nodes[3]:[nodes[4]],
		nodes[6]:[nodes[7]],nodes[7]:[nodes[8]],nodes[4]:[],nodes[8]:[],nodes[0]:[]}


# source = 5

def bfs(graph,source):
	global time,stack
	time+=1
	source.d_time=time
	source.color = 'Gray'
	stack.append(source.number)
	source.d = 0

	queue = deque()
	queue.append(source)

	while queue:
		q = queue.popleft()
		for v in graph[q]:
			if v.color=='White':
				time+=1
				v.d_time = time
				v.color='Gray'
				stack.append(v.number)
				v.d = q.d + 1
				v.pi = q
				queue.append(v)
		time+=1
		q.f_time=time
		q.color='Black'
		if q.number == stack[-1]:
			stack.pop()
		else:
			stack.append("Doesn't work")
		#F_time

source = nodes[5]

bfs(graph,source)

print(stack)
~~~
And that it does work for DFS as we see below the stack is empty at the end which means balanced parenthesis:
~~~python
import numpy as np
from collections import deque
import time

global time, stack
stack = deque()
time = 0


class Node:
	def __init__(self, number,d_time=None,f_time=None, pi=None, color='White'):
		self.name = str(number)
		self.d_time = d_time
		self.f_time = f_time
		self.pi = pi 
		self.color = color

	def __repr__(self):
		return self.name


nodes = [Node(0),Node(1),Node(2),Node(3),Node(4),Node(5),Node(6),Node(7),Node(8)]


graph = {nodes[5]:[nodes[1],nodes[6]],nodes[1]:[nodes[0],nodes[2]],nodes[2]:[nodes[3]],nodes[3]:[nodes[4]],
		nodes[6]:[nodes[7]],nodes[7]:[nodes[8]],nodes[4]:[],nodes[8]:[],nodes[0]:[]}



def dfs(graph,vertex):
	global time,stack
	print(vertex.name)

	time+=1
	vertex.d_time = time
	vertex.color = 'Gray'
	stack.append(vertex.name)


	for val in graph[vertex]:
		if val.color=='White':
			val.pi = vertex.name
			dfs(graph,val)
	time+=1
	vertex.f_time = time
	vertex.color='Black'
	print(stack)
	if vertex.name == stack[-1]:
		stack.pop()
	else:
		stack.append("Doesn't work")


# for val in nodes:
# 	if val.color=='White':
dfs(graph,nodes[5])

print(stack)

# for node in nodes:
# 	print(node.name, node.d_time,node.f_time,node.color)
~~~


5. moved to next week

keywords: clr, dfs, edges
6. 22-3-9
	Give a counterexample to the conjecture that if a directed graph G contains a path from u to v, then any depth-first search must result in v.d≤u.f

	a node gets f once it has no more unvisited outgoing edges. we need a case where u goes to v but u also finishes before v. That seems impossible if v is a descendant of u because u won't finish until v is discovered (and finished). My guess is it's some weird graph that's not a typical top down binary search tree


	22-3-10


	~~~python 
	nodes = [Node(0),Node(1),Node(2),Node(3),Node(4),Node(5),Node(6),Node(7),Node(8)]


graph = {nodes[5]:[nodes[1],nodes[6]],nodes[1]:[nodes[0],nodes[2]],nodes[2]:[nodes[3]],nodes[3]:[nodes[4]],
		nodes[6]:[nodes[7]],nodes[7]:[nodes[8]],nodes[4]:[],nodes[8]:[],nodes[0]:[nodes[1]]}



def dfs(graph,vertex):
	global time,stack

	time+=1
	vertex.d_time = time
	vertex.color = 'Gray'


	for val in graph[vertex]:
		if val.color=='White':
			print('Tree Edge from {} to {}'.format(vertex.name,val.name))
			val.pi = vertex.name
			dfs(graph,val)
		elif val.color=='Gray':
			print('Back Edge from {} to {}'.format(vertex.name,val.name))
		else:
			if vertex.d_time < val.d_time:
				print('Forward Edge from {} to {}'.format(vertex.name,val.name))
			else:
				print('Cross Edge from {} to {}'.format(vertex.name,val.name))

	time+=1
	vertex.f_time = time
	vertex.color='Black'


for val in nodes:
	if val.color=='White':
		dfs(graph,val)
	~~~
![[dfs_edges.jpeg]]


7 keywords: ballmer, microsoft, interview, game theory

There is a way to do it without simulation variance. For each of the 100 numbers, assume Ballmer picks that number and run the binary search strategy and calculate the payoff for that number. Each number has a 1/100 probability of being selected. Only need to run simulation 100 times instead of to infinity or whatever it takes to converge.

Below is optimal solution
~~~python
total_numbers = 100
amount_won = 5
number_of_ways = 1
profit = 0

while total_numbers > 0:
	profit+= (number_of_ways/100)*amount_won
	total_numbers-=number_of_ways
	if number_of_ways*2 > total_numbers:
		number_of_ways=total_numbers
	else:
		number_of_ways*=2


	amount_won-=1

print(profit)

#expected value is 20 cents
~~~
