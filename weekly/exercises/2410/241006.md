Implementing the sequence prediction model for baseball (take home interview)

Action space: fast, slow, curve, ...
State space: context (number of strikes, etc.)

# Basics
- The data has time steps. Each time step is a pitch in the sequence. 
- How should sequence be defined? IMO: temporal sequence of actions per game and pitcher (optionally, per game, pitcher and batter, but I prefer game and pitcher).
- All models should predict a probability distribution across the actions (fast, slow, curve,...).
- What measure should be used to evaluate any model?
	- Option-1: Hard accuracy. Take the mode of the predicted action distribution (the action with the highest probability). Treat this as the prediction. The model gets a score of $1$ if it matches the actual throw. It gets a score of $0$ if it doesn't.
	- Option-2: Soft accuracy. Calculate the KL divergence of the predicted distribution with the actual distribution (which is a vector with a 1 and all other entries 0). This reduces to log-likelihood.
- How should train-test split be performed? IMO: Split data into multiple sequences (per game and pitcher). Then, randomly sample 80% of the sequences for training. The rest of the sequences become testing.
# Baselining
The baseline models are really dumb and simple. Used as unit tests for main models. They are sequence only models and don't take into account the context at all.
- Baseline model-1: simple probability distribution across action space. Take entire training data, count the number of balls of each type. Then normalize to get probability distribution. Use this as the predicted distribution for each time step in evaluation.
- Baseline model-2: Markov chain. Create count matrix of actions transitioning to other actions. Normalize the count matrix across rows. Get the transition probability matrix. In each time step of the sequence, the row of this matrix indexed by the previous action becomes the probability vector.
- Baseline model-3: Player specific Markov chain. Create a global count matrix across all training data, $P$. And a player specific count matrix, $Q$. Create a new matrix, $P+wQ$ where $w$ is a weight associated with how much you want to emphasize the players data. Pick the value of $w$ that gives the best log-likelihood on the training data.
# Serious models
These models will take features into account. For now, we consider only one feature. The number of strikes: $X_i$. 
![[pitch_model.png|400]]

We can formulate this as a Markov decision process where an agent (the player) takes certain actions (decides what ball to throw).

The result says that we define a rewards matrix, $R(i,a)$ and a state transition matrix, $P(a)$ for each action. Then solve the linear program below to get the optimal policy, $\beta(a)$ per action. 
![[markov_decision_process.png|500]]

The prediction of the probability vector across the action space given the state, $i$ will be per $\beta_i$. Use this as the predicted vector and evaluate.